{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**PROJECT ARCHITECTURE**\n",
        "\n",
        "faiss_indexer.py: FAISS index creation and management.\n",
        "\n",
        "eml_extractor.py: Functions to extract EML content.\n",
        "\n",
        "classifier.py: LLM classification logic.\n",
        "\n",
        "main.py: The main script for querying and displaying results."
      ],
      "metadata": {
        "id": "sjw8YDhDsql_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "eml_extractor.py       # EML extraction functions\n"
      ],
      "metadata": {
        "id": "cKyAr16hqgr7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhDVZOYYngut"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from email import message_from_file\n",
        "\n",
        "def extract_eml_content(file_path):\n",
        "    \"\"\"Extracts subject and body text from an EML file.\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        msg = message_from_file(f)\n",
        "\n",
        "    subject = msg.get('Subject', '')\n",
        "    body = \"\"\n",
        "\n",
        "    if msg.is_multipart():\n",
        "        for part in msg.walk():\n",
        "            if part.get_content_type() == \"text/plain\":\n",
        "                body += part.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
        "    else:\n",
        "        body = msg.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
        "\n",
        "    return f\"Subject: {subject}\\n\\n{body}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "faiss_indexer.py       # FAISS indexing and search functions\n"
      ],
      "metadata": {
        "id": "fns3RXB5qwfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWjfBBV-oWHn",
        "outputId": "087fc49a-6609-48dc-b1aa-5dc87b5bdaf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import faiss\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# === Configuration ===\n",
        "FAISS_INDEX_FILE = \"/content/FAISS/faiss_index_classifications.idx\"\n",
        "EML_CSV_FILE = \"/content/eml_classification_mapping_cleaned.csv\"\n",
        "EMBED_MODEL = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "\n",
        "# ‚úÖ Function to create FAISS index if it doesn't exist\n",
        "def create_faiss_index(eml_df):\n",
        "    \"\"\"Creates and saves a FAISS index from EML classification CSV.\"\"\"\n",
        "    print(\"\\nüõ†Ô∏è Creating FAISS index...\")\n",
        "\n",
        "    try:\n",
        "        # ‚úÖ Extract email contents and create embeddings\n",
        "        emails = eml_df['File'].tolist()\n",
        "        embeddings = []\n",
        "\n",
        "        for eml_file in emails:\n",
        "            eml_path = f\"/content/synthetic_eml_files/{eml_file}\"\n",
        "\n",
        "            # Skip if the file doesn't exist\n",
        "            if not os.path.exists(eml_path):\n",
        "                print(f\"‚ùå Skipping {eml_file} (file not found)\")\n",
        "                continue\n",
        "\n",
        "            eml_content = extract_eml_content(eml_path)\n",
        "            embedding = EMBED_MODEL.encode(eml_content)\n",
        "            embeddings.append(embedding)\n",
        "\n",
        "        # ‚úÖ Convert embeddings to FAISS format\n",
        "        embeddings = np.array(embeddings).astype('float32')\n",
        "        dimension = embeddings.shape[1]\n",
        "\n",
        "        # ‚úÖ Create and save the FAISS index\n",
        "        faiss_index = faiss.IndexFlatL2(dimension)\n",
        "        faiss_index.add(embeddings)\n",
        "\n",
        "        os.makedirs(os.path.dirname(FAISS_INDEX_FILE), exist_ok=True)\n",
        "        faiss.write_index(faiss_index, FAISS_INDEX_FILE)\n",
        "\n",
        "        print(\"\\n‚úÖ FAISS index created and saved successfully!\")\n",
        "        return faiss_index\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creating FAISS index: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# ‚úÖ Function to load FAISS index (or create it)\n",
        "def load_faiss():\n",
        "    \"\"\"Loads FAISS index or creates it if it doesn't exist.\"\"\"\n",
        "    if os.path.exists(FAISS_INDEX_FILE):\n",
        "        print(\"\\n‚úÖ Loading FAISS index...\")\n",
        "        try:\n",
        "            faiss_index = faiss.read_index(FAISS_INDEX_FILE)\n",
        "            print(\"‚úÖ FAISS index loaded successfully!\")\n",
        "            return faiss_index\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading FAISS: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è FAISS index not found. Creating new index...\")\n",
        "        eml_df = load_eml_csv()\n",
        "\n",
        "        if eml_df is not None:\n",
        "            return create_faiss_index(eml_df)\n",
        "        else:\n",
        "            print(\"‚ùå Failed to create FAISS index (CSV not loaded).\")\n",
        "            return None\n",
        "\n",
        "\n",
        "\n",
        "# ‚úÖ FAISS Search with Mapping\n",
        "def search_faiss(embedding, faiss_index, mapping_df, top_k=5):\n",
        "    \"\"\"Searches FAISS index and retrieves mapped classifications.\"\"\"\n",
        "    # Ensure the embedding is in correct format\n",
        "    embedding = embedding.reshape(1, -1).astype('float32')\n",
        "\n",
        "    # Perform the FAISS search\n",
        "    distances, indices = faiss_index.search(embedding, top_k)\n",
        "\n",
        "    results = []\n",
        "    for i in range(len(indices[0])):\n",
        "        idx = indices[0][i]\n",
        "        dist = distances[0][i]\n",
        "\n",
        "        if idx < 0 or idx >= len(mapping_df):\n",
        "            continue  # Skip invalid indices\n",
        "\n",
        "        # ‚úÖ Retrieve classification from mapping CSV\n",
        "        file_name = mapping_df.iloc[idx]['File']\n",
        "        req_type = mapping_df.iloc[idx]['request_type']\n",
        "        sub_req_type = mapping_df.iloc[idx]['sub_request_type']\n",
        "\n",
        "        results.append((file_name, dist, req_type, sub_req_type))\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# ‚úÖ Function to include CSV data as context\n",
        "def get_csv_context(eml_df, max_rows=20):\n",
        "    \"\"\"Generates a textual context from the EML ‚Üí Classification CSV.\"\"\"\n",
        "    context = \"\\n--- Past Classifications ---\\n\"\n",
        "\n",
        "    # ‚úÖ Select a few random rows for diversity\n",
        "    sample_df = eml_df.sample(n=min(max_rows, len(eml_df)))\n",
        "\n",
        "    for _, row in sample_df.iterrows():\n",
        "        context += (\n",
        "            f\"Email: {row['File']}\\n\"\n",
        "            f\"Request Type: {row['request_type']}\\n\"\n",
        "            f\"Sub Request Type: {row['sub_request_type']}\\n\"\n",
        "            \"---------------------------------\\n\"\n",
        "        )\n",
        "\n",
        "    return context\n",
        "\n",
        "\n",
        "# ‚úÖ Main Query Function\n",
        "def query_eml(file_path, eml_df):\n",
        "    \"\"\"Classifies and searches for similar emails with CSV context.\"\"\"\n",
        "\n",
        "    print(\"\\n‚úÖ Extracting EML content...\")\n",
        "    eml_content = extract_eml_content(file_path)\n",
        "\n",
        "    # ‚úÖ Get CSV context\n",
        "    csv_context = get_csv_context(eml_df)\n",
        "\n",
        "    # ‚úÖ Combine email content with CSV context\n",
        "    full_prompt = f\"{csv_context}\\n--- New Email ---\\n{eml_content}\"\n",
        "\n",
        "    print(\"\\n‚úÖ Classifying with Gemini Pro...\")\n",
        "    req_type, sub_req_type, reason = classify_with_gemini(full_prompt)\n",
        "\n",
        "    print(\"\\n‚úÖ Generating embedding...\")\n",
        "    embedding = EMBED_MODEL.encode(eml_content)\n",
        "\n",
        "    print(\"\\n‚úÖ Searching FAISS for similar emails...\")\n",
        "    results = search_faiss(embedding, faiss_index, eml_df)\n",
        "\n",
        "    # ‚úÖ Extract ground truth classification from CSV\n",
        "    eml_file_name = file_path.split('/')[-1]\n",
        "    csv_match = eml_df[eml_df['File'] == eml_file_name]\n",
        "\n",
        "    csv_req_type = csv_match['request_type'].values[0] if not csv_match.empty else \"Unknown\"\n",
        "    csv_sub_req_type = csv_match['sub_request_type'].values[0] if not csv_match.empty else \"Unknown\"\n",
        "\n",
        "    # === Display results\n",
        "    print(\"\\nüîç **Query Results:**\")\n",
        "    print(f\"üîπ **LLM Classification:**\")\n",
        "    print(f\"   - Request Type: {req_type}\")\n",
        "    print(f\"   - Sub Request Type: {sub_req_type}\")\n",
        "    print(f\"   - Reason: {reason}\\n\")\n",
        "\n",
        "    print(f\"üîπ **Ground Truth from CSV:**\")\n",
        "    print(f\"   - Request Type: {csv_req_type}\")\n",
        "    print(f\"   - Sub Request Type: {csv_sub_req_type}\")\n"
      ],
      "metadata": {
        "id": "erY9ZmbRnoCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "classifier.py          # Gemini Pro classification functions\n"
      ],
      "metadata": {
        "id": "cdvF1oo3qzrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCReRGA1nqHP",
        "outputId": "d3de51ee-d943-4c75-b679-b9b20aae6a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.11/dist-packages (0.18.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from fuzzywuzzy import fuzz\n",
        "import google.generativeai as genai\n",
        "\n",
        "# === Configuration ===\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"use gemini api key\"  # Replace with your key\n",
        "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "# ‚úÖ Flexible schema\n",
        "SCHEMA = {\n",
        "    \"Adjustment\": [],\n",
        "    \"AU Transfer\": [],\n",
        "    \"Closing Notice\": [\"Reallocation fees\", \"Amendment fees\", \"Reallocation principal\"],\n",
        "    \"Commitment Change\": [\"Cashless roll\", \"Decrease\", \"Increase\"],\n",
        "    \"Fee Payment\": [\"Ongoing fee\", \"Letter of credit fee\"],\n",
        "    \"Money Movement-Inbound\": [\"Principal\", \"Interest\", \"Principal and Interest\", \"Principal, Interest, and Fee\"],\n",
        "    \"Money Movement-Outbound\": [\"Timebound\", \"Foreign currency\"]\n",
        "}\n",
        "\n",
        "def normalize_text(text):\n",
        "    \"\"\"Normalize and clean text for matching.\"\"\"\n",
        "    return text.strip().lower().replace('-', ' ').replace('_', ' ')\n",
        "\n",
        "def fuzzy_match(target, candidates, threshold=85):\n",
        "    \"\"\"Fuzzy match a target against multiple candidates.\"\"\"\n",
        "    best_match = max(candidates, key=lambda c: fuzz.ratio(target, c))\n",
        "    if fuzz.ratio(target, best_match) >= threshold:\n",
        "        return best_match\n",
        "    return \"Unknown\"\n",
        "\n",
        "def classify_with_gemini(eml_content):\n",
        "    \"\"\"Classifies EML content using Gemini Pro with fuzzy schema matching.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Classify the email into:\n",
        "- **Request Type** and **Sub Request Type** using the following schema:\n",
        "{SCHEMA}\n",
        "\n",
        "- **Important:**\n",
        "    - You **must classify** the email strictly according to the schema.\n",
        "    - The `Request Type` should always be one of the main categories.\n",
        "    - The `Sub Request Type` must be a valid subcategory under the corresponding `Request Type`.\n",
        "    - If no match is found, respond with `Unknown` for both types.\n",
        "\n",
        "- **Reason:**\n",
        "    - Provide a clear reason for the classification.\n",
        "\n",
        "Email content:\n",
        "{eml_content}\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
        "        response = model.generate_content(prompt)\n",
        "\n",
        "        if not response or not response.text:\n",
        "            return \"Unknown\", \"Unknown\", \"No reason provided\"\n",
        "\n",
        "        # ‚úÖ Extract values using regex\n",
        "        req_type = re.search(r\"Request Type:\\s*(.*)\", response.text)\n",
        "        sub_req_type = re.search(r\"Sub Request Type:\\s*(.*)\", response.text)\n",
        "        reason_match = re.search(r\"Reason:\\s*(.*)\", response.text, re.DOTALL)\n",
        "\n",
        "        req_type = req_type.group(1).strip() if req_type else \"Unknown\"\n",
        "        sub_req_type = sub_req_type.group(1).strip() if sub_req_type else \"Unknown\"\n",
        "        reason = reason_match.group(1).strip() if reason_match else \"No reason provided\"\n",
        "\n",
        "        # ‚úÖ Normalize\n",
        "        normalized_req = normalize_text(req_type)\n",
        "        normalized_sub_req = normalize_text(sub_req_type)\n",
        "\n",
        "        # ‚úÖ Fuzzy match request type\n",
        "        matched_req_type = \"Unknown\"\n",
        "        matched_sub_req = \"Unknown\"\n",
        "\n",
        "        for req, subs in SCHEMA.items():\n",
        "            if fuzz.ratio(normalized_req, normalize_text(req)) >= 85:\n",
        "                matched_req_type = req\n",
        "\n",
        "                # Fuzzy match sub-request type\n",
        "                if subs:\n",
        "                    matched_sub_req = fuzzy_match(normalized_sub_req, [normalize_text(sub) for sub in subs])\n",
        "\n",
        "        return matched_req_type, matched_sub_req, reason\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error in Gemini Pro classification: {e}\")\n",
        "        return \"Unknown\", \"Unknown\", \"No reason provided\"\n"
      ],
      "metadata": {
        "id": "44ljzmnRnsvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main.py"
      ],
      "metadata": {
        "id": "cvP4xbh5_1AM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Load FAISS and EML CSV\n",
        "EML_FILE = \"/content/synthetic_eml_files/Fee_Payment_Loc_1.eml\"\n",
        "faiss_index = load_faiss()\n",
        "eml_df = pd.read_csv(EML_CSV_FILE)\n",
        "\n",
        "# ‚úÖ Run Query\n",
        "if faiss_index is not None and eml_df is not None:\n",
        "    query_eml(EML_FILE, eml_df)\n",
        "else:\n",
        "    print(\"‚ùå Failed to load FAISS or EML CSV.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "hl6Ebrvi1dVe",
        "outputId": "4e248051-1b68-480b-e9d2-aa746b72d5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Loading FAISS index...\n",
            "‚úÖ FAISS index loaded successfully!\n",
            "\n",
            "‚úÖ Extracting EML content...\n",
            "\n",
            "‚úÖ Classifying with Gemini Pro...\n",
            "\n",
            "‚úÖ Generating embedding...\n",
            "\n",
            "‚úÖ Searching FAISS for similar emails...\n",
            "\n",
            "üîç **Query Results:**\n",
            "üîπ **LLM Classification:**\n",
            "   - Request Type: Fee Payment\n",
            "   - Sub Request Type: ongoing fee\n",
            "   - Reason: The email explicitly questions an ongoing \"Line of Credit Fee\" and seeks clarification on its nature and potential waiver. This aligns with the \"Fee Payment\" request type and the \"Ongoing fee\" sub-type.\n",
            "\n",
            "üîπ **Ground Truth from CSV:**\n",
            "   - Request Type: Unknown\n",
            "   - Sub Request Type: Unknown\n"
          ]
        }
      ]
    }
  ]
}
