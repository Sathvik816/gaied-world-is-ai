{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7wpac2lsbhumZhACPJedM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sathvik816/gaied-world-is-ai/blob/main/final_hackathon2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROJECT ARCHITECTURE**\n",
        "\n",
        "faiss_indexer.py: FAISS index creation and management.\n",
        "\n",
        "eml_extractor.py: Functions to extract EML content.\n",
        "\n",
        "classifier.py: LLM classification logic.\n",
        "\n",
        "main.py: The main script for querying and displaying results."
      ],
      "metadata": {
        "id": "sjw8YDhDsql_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "eml_extractor.py       # EML extraction functions\n"
      ],
      "metadata": {
        "id": "cKyAr16hqgr7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dhDVZOYYngut"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from email import message_from_file\n",
        "\n",
        "def extract_eml_content(file_path):\n",
        "    \"\"\"Extracts subject and body text from an EML file.\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        msg = message_from_file(f)\n",
        "\n",
        "    subject = msg.get('Subject', '')\n",
        "    body = \"\"\n",
        "\n",
        "    if msg.is_multipart():\n",
        "        for part in msg.walk():\n",
        "            if part.get_content_type() == \"text/plain\":\n",
        "                body += part.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
        "    else:\n",
        "        body = msg.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
        "\n",
        "    return f\"Subject: {subject}\\n\\n{body}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "faiss_indexer.py       # FAISS indexing and search functions\n"
      ],
      "metadata": {
        "id": "fns3RXB5qwfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWjfBBV-oWHn",
        "outputId": "265e3ae8-8286-4d50-c90a-d1637ee8f67e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import faiss\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# === Configuration ===\n",
        "FAISS_INDEX_FILE = \"/content/FAISS/faiss_index_classifications.idx\"\n",
        "EML_CSV_FILE = \"/content/eml_classification_mapping_cleaned.csv\"\n",
        "EMBED_MODEL = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "\n",
        "# ‚úÖ Function to create FAISS index if it doesn't exist\n",
        "def create_faiss_index(eml_df):\n",
        "    \"\"\"Creates and saves a FAISS index from EML classification CSV.\"\"\"\n",
        "    print(\"\\nüõ†Ô∏è Creating FAISS index...\")\n",
        "\n",
        "    try:\n",
        "        # ‚úÖ Extract email contents and create embeddings\n",
        "        emails = eml_df['File'].tolist()\n",
        "        embeddings = []\n",
        "\n",
        "        for eml_file in emails:\n",
        "            eml_path = f\"/content/synthetic_eml_files/{eml_file}\"\n",
        "\n",
        "            # Skip if the file doesn't exist\n",
        "            if not os.path.exists(eml_path):\n",
        "                print(f\"‚ùå Skipping {eml_file} (file not found)\")\n",
        "                continue\n",
        "\n",
        "            eml_content = extract_eml_content(eml_path)\n",
        "            embedding = EMBED_MODEL.encode(eml_content)\n",
        "            embeddings.append(embedding)\n",
        "\n",
        "        # ‚úÖ Convert embeddings to FAISS format\n",
        "        embeddings = np.array(embeddings).astype('float32')\n",
        "        dimension = embeddings.shape[1]\n",
        "\n",
        "        # ‚úÖ Create and save the FAISS index\n",
        "        faiss_index = faiss.IndexFlatL2(dimension)\n",
        "        faiss_index.add(embeddings)\n",
        "\n",
        "        os.makedirs(os.path.dirname(FAISS_INDEX_FILE), exist_ok=True)\n",
        "        faiss.write_index(faiss_index, FAISS_INDEX_FILE)\n",
        "\n",
        "        print(\"\\n‚úÖ FAISS index created and saved successfully!\")\n",
        "        return faiss_index\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creating FAISS index: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# ‚úÖ Function to load FAISS index (or create it)\n",
        "def load_faiss():\n",
        "    \"\"\"Loads FAISS index or creates it if it doesn't exist.\"\"\"\n",
        "    if os.path.exists(FAISS_INDEX_FILE):\n",
        "        print(\"\\n‚úÖ Loading FAISS index...\")\n",
        "        try:\n",
        "            faiss_index = faiss.read_index(FAISS_INDEX_FILE)\n",
        "            print(\"‚úÖ FAISS index loaded successfully!\")\n",
        "            return faiss_index\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading FAISS: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è FAISS index not found. Creating new index...\")\n",
        "        eml_df = load_eml_csv()\n",
        "\n",
        "        if eml_df is not None:\n",
        "            return create_faiss_index(eml_df)\n",
        "        else:\n",
        "            print(\"‚ùå Failed to create FAISS index (CSV not loaded).\")\n",
        "            return None\n",
        "\n",
        "\n",
        "\n",
        "# ‚úÖ FAISS Search with Mapping\n",
        "def search_faiss(embedding, faiss_index, mapping_df, top_k=5):\n",
        "    \"\"\"Searches FAISS index and retrieves mapped classifications.\"\"\"\n",
        "    # Ensure the embedding is in correct formatimport os\n",
        "import faiss\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# === Configuration ===\n",
        "FAISS_INDEX_FILE = \"/content/FAISS/faiss_index_classifications.idx\"\n",
        "EML_CSV_FILE = \"/content/eml_classification_mapping_cleaned.csv\"\n",
        "EMBED_MODEL = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "\n",
        "# ‚úÖ Function to load the CSV\n",
        "def load_eml_csv():\n",
        "    \"\"\"Loads the EML classification mapping CSV into a DataFrame.\"\"\"\n",
        "    try:\n",
        "        print(\"\\n‚úÖ Loading EML CSV...\")\n",
        "        eml_df = pd.read_csv(EML_CSV_FILE)\n",
        "\n",
        "        # ‚úÖ Check if the necessary columns exist\n",
        "        required_columns = {'File', 'request_type', 'sub_request_type'}\n",
        "        if not required_columns.issubset(eml_df.columns):\n",
        "            print(f\"‚ùå Missing required columns in CSV: {required_columns - set(eml_df.columns)}\")\n",
        "            return None\n",
        "\n",
        "        print(f\"‚úÖ CSV loaded with {len(eml_df)} records.\")\n",
        "        return eml_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading CSV: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# ‚úÖ Function to create FAISS index\n",
        "def create_faiss_index(eml_df):\n",
        "    \"\"\"Creates and saves a FAISS index from EML classification CSV.\"\"\"\n",
        "    print(\"\\nüõ†Ô∏è Creating FAISS index...\")\n",
        "\n",
        "    try:\n",
        "        embeddings = []\n",
        "        valid_files = 0\n",
        "\n",
        "        for eml_file in eml_df['File']:\n",
        "            eml_path = eml_file.strip()  # Use full path from CSV\n",
        "\n",
        "            if not os.path.exists(eml_path):\n",
        "                print(f\"‚ùå Skipping {eml_path} (file not found)\")\n",
        "                continue\n",
        "\n",
        "            valid_files += 1\n",
        "\n",
        "            eml_content = extract_eml_content(eml_path)\n",
        "            embedding = EMBED_MODEL.encode(eml_content)\n",
        "            embeddings.append(embedding)\n",
        "\n",
        "        # ‚úÖ Handle case with no valid files\n",
        "        if not embeddings:\n",
        "            print(\"‚ùå No valid EML files found. Cannot create FAISS index.\")\n",
        "            return None\n",
        "\n",
        "        # ‚úÖ Convert embeddings to FAISS format\n",
        "        embeddings = np.array(embeddings).astype('float32')\n",
        "        dimension = embeddings.shape[1]\n",
        "\n",
        "        # ‚úÖ Create and save the FAISS index\n",
        "        faiss_index = faiss.IndexFlatL2(dimension)\n",
        "        faiss_index.add(embeddings)\n",
        "\n",
        "        os.makedirs(os.path.dirname(FAISS_INDEX_FILE), exist_ok=True)\n",
        "        faiss.write_index(faiss_index, FAISS_INDEX_FILE)\n",
        "\n",
        "        print(f\"\\n‚úÖ FAISS index created with {valid_files} valid files and saved successfully!\")\n",
        "        return faiss_index\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creating FAISS index: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# ‚úÖ Function to load or create FAISS index\n",
        "def load_faiss():\n",
        "    \"\"\"Loads FAISS index or creates it if it doesn't exist.\"\"\"\n",
        "    if os.path.exists(FAISS_INDEX_FILE):\n",
        "        print(\"\\n‚úÖ Loading FAISS index...\")\n",
        "        try:\n",
        "            faiss_index = faiss.read_index(FAISS_INDEX_FILE)\n",
        "            print(\"‚úÖ FAISS index loaded successfully!\")\n",
        "            return faiss_index\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading FAISS: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è FAISS index not found. Creating new index...\")\n",
        "        eml_df = load_eml_csv()\n",
        "\n",
        "        if eml_df is not None:\n",
        "            return create_faiss_index(eml_df)\n",
        "        else:\n",
        "            print(\"‚ùå Failed to create FAISS index (CSV not loaded).\")\n",
        "            return None\n",
        "\n",
        "\n",
        "# ‚úÖ FAISS Search with Mapping\n",
        "def search_faiss(embedding, faiss_index, mapping_df, top_k=5):\n",
        "    \"\"\"Searches FAISS index and retrieves mapped classifications.\"\"\"\n",
        "    if faiss_index is None:\n",
        "        print(\"‚ùå FAISS index not loaded.\")\n",
        "        return []\n",
        "\n",
        "    embedding = embedding.reshape(1, -1).astype('float32')\n",
        "    distances, indices = faiss_index.search(embedding, top_k)\n",
        "\n",
        "    results = []\n",
        "    for i in range(len(indices[0])):\n",
        "        idx = indices[0][i]\n",
        "        dist = distances[0][i]\n",
        "\n",
        "        if idx < 0 or idx >= len(mapping_df):\n",
        "            continue\n",
        "\n",
        "        # ‚úÖ Retrieve classification from mapping CSV\n",
        "        file_name = mapping_df.iloc[idx]['File']\n",
        "        req_type = mapping_df.iloc[idx]['request_type']\n",
        "        sub_req_type = mapping_df.iloc[idx]['sub_request_type']\n",
        "\n",
        "        results.append((file_name, dist, req_type, sub_req_type))\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# ‚úÖ Function to include CSV data as context\n",
        "def get_csv_context(eml_df, max_rows=5):\n",
        "    \"\"\"Generates a textual context from the EML ‚Üí Classification CSV.\"\"\"\n",
        "    context = \"\\n--- Past Classifications ---\\n\"\n",
        "\n",
        "    sample_df = eml_df.sample(n=min(max_rows, len(eml_df)))\n",
        "\n",
        "    for _, row in sample_df.iterrows():\n",
        "        context += (\n",
        "            f\"Email: {row['File']}\\n\"\n",
        "            f\"Request Type: {row['request_type']}\\n\"\n",
        "            f\"Sub Request Type: {row['sub_request_type']}\\n\"\n",
        "            \"---------------------------------\\n\"\n",
        "        )\n",
        "\n",
        "    return context\n",
        "\n",
        "\n",
        "# ‚úÖ Main Query Function\n",
        "def query_eml(file_path, eml_df):\n",
        "    \"\"\"Classifies and searches for similar emails with CSV context.\"\"\"\n",
        "\n",
        "    print(\"\\n‚úÖ Extracting EML content...\")\n",
        "    eml_content = extract_eml_content(file_path)\n",
        "\n",
        "    # ‚úÖ Get CSV context\n",
        "    csv_context = get_csv_context(eml_df)\n",
        "\n",
        "    # ‚úÖ Combine email content with CSV context\n",
        "    full_prompt = f\"{csv_context}\\n--- New Email ---\\n{eml_content}\"\n",
        "\n",
        "    print(\"\\n‚úÖ Classifying with Gemini Pro...\")\n",
        "    req_type, sub_req_type, reason = classify_with_gemini(full_prompt)\n",
        "\n",
        "    print(\"\\n‚úÖ Generating embedding...\")\n",
        "    embedding = EMBED_MODEL.encode(eml_content)\n",
        "\n",
        "    print(\"\\n‚úÖ Searching FAISS for similar emails...\")\n",
        "    faiss_index = load_faiss()\n",
        "\n",
        "    results = search_faiss(embedding, faiss_index, eml_df)\n",
        "\n",
        "    # ‚úÖ Extract ground truth classification from CSV\n",
        "    eml_file_name = os.path.basename(file_path)\n",
        "    csv_match = eml_df[eml_df['File'].str.contains(eml_file_name)]\n",
        "\n",
        "    csv_req_type = csv_match['request_type'].values[0] if not csv_match.empty else \"Unknown\"\n",
        "    csv_sub_req_type = csv_match['sub_request_type'].values[0] if not csv_match.empty else \"Unknown\"\n",
        "\n",
        "    # === Display results\n",
        "    print(\"\\nüîç **Query Results:**\")\n",
        "    print(f\"üîπ **LLM Classification:**\")\n",
        "    print(f\"   - Request Type: {req_type}\")\n",
        "    print(f\"   - Sub Request Type: {sub_req_type}\")\n",
        "    print(f\"   - Reason: {reason}\\n\")\n",
        "\n",
        "    print(f\"üîπ **Ground Truth from CSV:**\")\n",
        "    print(f\"   - Request Type: {csv_req_type}\")\n",
        "    print(f\"   - Sub Request Type: {csv_sub_req_type}\")\n",
        "\n",
        "    embedding = embedding.reshape(1, -1).astype('float32')\n",
        "\n",
        "    # Perform the FAISS search\n",
        "    distances, indices = faiss_index.search(embedding, top_k)\n",
        "\n",
        "    results = []\n",
        "    for i in range(len(indices[0])):\n",
        "        idx = indices[0][i]\n",
        "        dist = distances[0][i]\n",
        "\n",
        "        if idx < 0 or idx >= len(mapping_df):\n",
        "            continue  # Skip invalid indices\n",
        "\n",
        "        # ‚úÖ Retrieve classification from mapping CSV\n",
        "        file_name = mapping_df.iloc[idx]['File']\n",
        "        req_type = mapping_df.iloc[idx]['request_type']\n",
        "        sub_req_type = mapping_df.iloc[idx]['sub_request_type']\n",
        "\n",
        "        results.append((file_name, dist, req_type, sub_req_type))\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# ‚úÖ Function to include CSV data as context\n",
        "def get_csv_context(eml_df, max_rows=5):\n",
        "    \"\"\"Generates a textual context from the EML ‚Üí Classification CSV.\"\"\"\n",
        "    context = \"\\n--- Past Classifications ---\\n\"\n",
        "\n",
        "    # ‚úÖ Select a few random rows for diversity\n",
        "    sample_df = eml_df.sample(n=min(max_rows, len(eml_df)))\n",
        "\n",
        "    for _, row in sample_df.iterrows():\n",
        "        context += (\n",
        "            f\"Email: {row['File']}\\n\"\n",
        "            f\"Request Type: {row['request_type']}\\n\"\n",
        "            f\"Sub Request Type: {row['sub_request_type']}\\n\"\n",
        "            \"---------------------------------\\n\"\n",
        "        )\n",
        "\n",
        "    return context\n",
        "\n",
        "\n",
        "# ‚úÖ Main Query Function\n",
        "def query_eml(file_path, eml_df):\n",
        "    \"\"\"Classifies and searches for similar emails with CSV context.\"\"\"\n",
        "\n",
        "    print(\"\\n‚úÖ Extracting EML content...\")\n",
        "    eml_content = extract_eml_content(file_path)\n",
        "\n",
        "    # ‚úÖ Get CSV context\n",
        "    csv_context = get_csv_context(eml_df)\n",
        "\n",
        "    # ‚úÖ Combine email content with CSV context\n",
        "    full_prompt = f\"{csv_context}\\n--- New Email ---\\n{eml_content}\"\n",
        "\n",
        "    print(\"\\n‚úÖ Classifying with Gemini Pro...\")\n",
        "    req_type, sub_req_type, reason = classify_with_gemini(full_prompt)\n",
        "\n",
        "    print(\"\\n‚úÖ Generating embedding...\")\n",
        "    embedding = EMBED_MODEL.encode(eml_content)\n",
        "\n",
        "    print(\"\\n‚úÖ Searching FAISS for similar emails...\")\n",
        "    results = search_faiss(embedding, faiss_index, eml_df)\n",
        "\n",
        "    # ‚úÖ Extract ground truth classification from CSV\n",
        "    eml_file_name = file_path.split('/')[-1]\n",
        "    csv_match = eml_df[eml_df['File'] == eml_file_name]\n",
        "\n",
        "    csv_req_type = csv_match['request_type'].values[0] if not csv_match.empty else \"Unknown\"\n",
        "    csv_sub_req_type = csv_match['sub_request_type'].values[0] if not csv_match.empty else \"Unknown\"\n",
        "\n",
        "    # === Display results\n",
        "    print(\"\\nüîç **Query Results:**\")\n",
        "    print(f\"üîπ **LLM Classification:**\")\n",
        "    print(f\"   - Request Type: {req_type}\")\n",
        "    print(f\"   - Sub Request Type: {sub_req_type}\")\n",
        "    print(f\"   - Reason: {reason}\\n\")\n",
        "\n",
        "    print(f\"üîπ **Ground Truth from CSV:**\")\n",
        "    print(f\"   - Request Type: {csv_req_type}\")\n",
        "    print(f\"   - Sub Request Type: {csv_sub_req_type}\")\n"
      ],
      "metadata": {
        "id": "erY9ZmbRnoCJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "classifier.py          # Gemini Pro classification functions\n"
      ],
      "metadata": {
        "id": "cdvF1oo3qzrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCReRGA1nqHP",
        "outputId": "96d902d6-0801-4ca2-ce15-973371d1bc31"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.11/dist-packages (0.18.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from fuzzywuzzy import fuzz\n",
        "import google.generativeai as genai\n",
        "\n",
        "# === Configuration ===\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyDl4zitAJPnmRXLwgpeVzSDAvqIxqKg75g\"  # Replace with your key\n",
        "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "# ‚úÖ Flexible schema\n",
        "SCHEMA = {\n",
        "    \"Adjustment\": [],\n",
        "    \"AU Transfer\": [],\n",
        "    \"Closing Notice\": [\"Reallocation fees\", \"Amendment fees\", \"Reallocation principal\"],\n",
        "    \"Commitment Change\": [\"Cashless roll\", \"Decrease\", \"Increase\"],\n",
        "    \"Fee Payment\": [\"Ongoing fee\", \"Letter of credit fee\"],\n",
        "    \"Money Movement-Inbound\": [\"Principal\", \"Interest\", \"Principal and Interest\", \"Principal, Interest, and Fee\"],\n",
        "    \"Money Movement-Outbound\": [\"Timebound\", \"Foreign currency\"]\n",
        "}\n",
        "\n",
        "def normalize_text(text):\n",
        "    \"\"\"Normalize and clean text for matching.\"\"\"\n",
        "    return text.strip().lower().replace('-', ' ').replace('_', ' ')\n",
        "\n",
        "def fuzzy_match(target, candidates, threshold=85):\n",
        "    \"\"\"Fuzzy match a target against multiple candidates.\"\"\"\n",
        "    best_match = max(candidates, key=lambda c: fuzz.ratio(target, c))\n",
        "    if fuzz.ratio(target, best_match) >= threshold:\n",
        "        return best_match\n",
        "    return \"Unknown\"\n",
        "\n",
        "def classify_with_gemini(eml_content):\n",
        "    \"\"\"Classifies EML content using Gemini Pro with fuzzy schema matching.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Classify the email into:\n",
        "- **Request Type** and **Sub Request Type** using the following schema:\n",
        "{SCHEMA}\n",
        "\n",
        "- **Important:**\n",
        "    - You **must classify** the email strictly according to the schema.\n",
        "    - The `Request Type` should always be one of the main categories.\n",
        "    - The `Sub Request Type` must be a valid subcategory under the corresponding `Request Type`.\n",
        "    - If no match is found, respond with `Unknown` for both types.\n",
        "\n",
        "- **Reason:**\n",
        "    - Provide a clear reason for the classification.\n",
        "\n",
        "Email content:\n",
        "{eml_content}\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
        "        response = model.generate_content(prompt)\n",
        "\n",
        "        if not response or not response.text:\n",
        "            return \"Unknown\", \"Unknown\", \"No reason provided\"\n",
        "\n",
        "        # ‚úÖ Extract values using regex\n",
        "        req_type = re.search(r\"Request Type:\\s*(.*)\", response.text)\n",
        "        sub_req_type = re.search(r\"Sub Request Type:\\s*(.*)\", response.text)\n",
        "        reason_match = re.search(r\"Reason:\\s*(.*)\", response.text, re.DOTALL)\n",
        "\n",
        "        req_type = req_type.group(1).strip() if req_type else \"Unknown\"\n",
        "        sub_req_type = sub_req_type.group(1).strip() if sub_req_type else \"Unknown\"\n",
        "        reason = reason_match.group(1).strip() if reason_match else \"No reason provided\"\n",
        "\n",
        "        # ‚úÖ Normalize\n",
        "        normalized_req = normalize_text(req_type)\n",
        "        normalized_sub_req = normalize_text(sub_req_type)\n",
        "\n",
        "        # ‚úÖ Fuzzy match request type\n",
        "        matched_req_type = \"Unknown\"\n",
        "        matched_sub_req = \"Unknown\"\n",
        "\n",
        "        for req, subs in SCHEMA.items():\n",
        "            if fuzz.ratio(normalized_req, normalize_text(req)) >= 85:\n",
        "                matched_req_type = req\n",
        "\n",
        "                # Fuzzy match sub-request type\n",
        "                if subs:\n",
        "                    matched_sub_req = fuzzy_match(normalized_sub_req, [normalize_text(sub) for sub in subs])\n",
        "\n",
        "        return matched_req_type, matched_sub_req, reason\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error in Gemini Pro classification: {e}\")\n",
        "        return \"Unknown\", \"Unknown\", \"No reason provided\"\n"
      ],
      "metadata": {
        "id": "44ljzmnRnsvs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Load FAISS and EML CSV\n",
        "EML_FILE = \"/content/synthetic_eml_files/AdjustmentRequestTypeSampleFile1.eml\"\n",
        "faiss_index = load_faiss()\n",
        "eml_df = load_eml_csv()\n",
        "\n",
        "# ‚úÖ Run Query\n",
        "if faiss_index is not None and eml_df is not None:\n",
        "    query_eml(EML_FILE, eml_df)\n",
        "else:\n",
        "    print(\"‚ùå Failed to load FAISS or EML CSV.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "hl6Ebrvi1dVe",
        "outputId": "942c6bb5-12a3-4a65-b363-019197cdd0d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Loading FAISS index...\n",
            "‚úÖ FAISS index loaded successfully!\n",
            "\n",
            "‚úÖ Loading EML CSV...\n",
            "‚úÖ CSV loaded with 21 records.\n",
            "\n",
            "‚úÖ Extracting EML content...\n",
            "\n",
            "‚úÖ Classifying with Gemini Pro...\n",
            "\n",
            "‚úÖ Generating embedding...\n",
            "\n",
            "‚úÖ Searching FAISS for similar emails...\n",
            "\n",
            "üîç **Query Results:**\n",
            "üîπ **LLM Classification:**\n",
            "   - Request Type: Adjustment\n",
            "   - Sub Request Type: Unknown\n",
            "   - Reason: The email explicitly states \"Request for Adjustment\" and describes an incorrect transaction posting requiring a refund.  Since \"Adjustment\" is a top-level category in the schema and has no subcategories, the Sub Request Type is an empty list.\n",
            "\n",
            "üîπ **Ground Truth from CSV:**\n",
            "   - Request Type: Unknown\n",
            "   - Sub Request Type: Unknown\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "main.py                # Main script to run the query"
      ],
      "metadata": {
        "id": "IE7PLg7dq3KX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/synthetic_eml_files/*.eml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cCj28Rt9PgO",
        "outputId": "d42e29f1-1728-4019-b076-096958f336dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/synthetic_eml_files/AdjustmentRequestTypeSampleFile1.eml\n",
            "/content/synthetic_eml_files/AdjustmentRequestTypeSampleFile2.eml\n",
            "/content/synthetic_eml_files/AdjustmentRequestTypeSampleFile3.eml\n",
            "/content/synthetic_eml_files/CommitmentChangeCashlessSamplefile1.eml\n",
            "/content/synthetic_eml_files/CommitmentChangeCashlessSamplefile2.eml\n",
            "/content/synthetic_eml_files/CommitmentChangeCashlessSamplefile3.eml\n",
            "/content/synthetic_eml_files/CommitmentChangeCashlessSamplefile4.eml\n",
            "/content/synthetic_eml_files/CommitmentChangeDecreaseSampleFile1.eml\n",
            "/content/synthetic_eml_files/CommitmentChangeDecreaseSampleFile2.eml\n",
            "/content/synthetic_eml_files/CommitmentChangeDecreaseSampleFile3.eml\n",
            "/content/synthetic_eml_files/CommitmentChangeIncreaseSampleFile1.eml\n",
            "/content/synthetic_eml_files/CommitmentChangeIncreaseSampleFile2.eml\n",
            "/content/synthetic_eml_files/CommitmentChangeIncreaseSampleFile3.eml\n",
            "/content/synthetic_eml_files/Fee_Payment_Loc_1.eml\n",
            "/content/synthetic_eml_files/Fee_Payment_Loc_2.eml\n",
            "/content/synthetic_eml_files/Fee_Payment_Ongoing_Fee_1.eml\n",
            "/content/synthetic_eml_files/Fee_Payment_Ongoing_Fee_2.eml\n",
            "/content/synthetic_eml_files/Fee_Payment_Ongoing_Fee_3.eml\n",
            "/content/synthetic_eml_files/Money_Movement_Outbound_Foreign_Currency_1.eml\n",
            "/content/synthetic_eml_files/Money_Movement_Outbound_Foreign_Currency_2.eml\n",
            "/content/synthetic_eml_files/Money_Movement_Outbound_Foreign_Currency_3.eml\n",
            "/content/synthetic_eml_files/Money_Movement_Outbound_Timebound_1.eml\n",
            "/content/synthetic_eml_files/Money_Movement_Outbound_Timebound_2.eml\n",
            "/content/synthetic_eml_files/sample1.eml\n",
            "/content/synthetic_eml_files/sample1_variant_10.eml\n",
            "/content/synthetic_eml_files/sample1_variant_1.eml\n",
            "/content/synthetic_eml_files/sample1_variant_2.eml\n",
            "/content/synthetic_eml_files/sample1_variant_3.eml\n",
            "/content/synthetic_eml_files/sample1_variant_4.eml\n",
            "/content/synthetic_eml_files/sample1_variant_5.eml\n",
            "/content/synthetic_eml_files/sample1_variant_6.eml\n",
            "/content/synthetic_eml_files/sample1_variant_7.eml\n",
            "/content/synthetic_eml_files/sample1_variant_8.eml\n",
            "/content/synthetic_eml_files/sample1_variant_9.eml\n",
            "/content/synthetic_eml_files/sample2.eml\n",
            "/content/synthetic_eml_files/sample2_variant_10.eml\n",
            "/content/synthetic_eml_files/sample2_variant_2.eml\n",
            "/content/synthetic_eml_files/sample2_variant_3.eml\n",
            "/content/synthetic_eml_files/sample2_variant_4.eml\n",
            "/content/synthetic_eml_files/sample2_variant_5.eml\n",
            "/content/synthetic_eml_files/sample2_variant_6.eml\n",
            "/content/synthetic_eml_files/sample2_variant_7.eml\n",
            "/content/synthetic_eml_files/sample2_variant_8.eml\n",
            "/content/synthetic_eml_files/sample2_variant_9.eml\n",
            "/content/synthetic_eml_files/variant_1_Fee_Payment_Loc_1.eml\n",
            "/content/synthetic_eml_files/variant_1_Fee_Payment_Loc_2.eml\n",
            "/content/synthetic_eml_files/variant_1_Fee_Payment_Ongoing_Fee_1.eml\n",
            "/content/synthetic_eml_files/variant_1_Fee_Payment_Ongoing_Fee_2.eml\n",
            "/content/synthetic_eml_files/variant_1_Fee_Payment_Ongoing_Fee_3.eml\n",
            "/content/synthetic_eml_files/variant_2_Fee_Payment_Loc_1.eml\n",
            "/content/synthetic_eml_files/variant_2_Fee_Payment_Loc_2.eml\n",
            "/content/synthetic_eml_files/variant_2_Fee_Payment_Ongoing_Fee_1.eml\n",
            "/content/synthetic_eml_files/variant_2_Fee_Payment_Ongoing_Fee_2.eml\n",
            "/content/synthetic_eml_files/variant_2_Fee_Payment_Ongoing_Fee_3.eml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fRKmolX19PPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import faiss\n",
        "# import pandas as pd\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# # === Configuration ===\n",
        "# EML_FILE = \"/content/synthetic_eml_files/AdjustmentRequestTypeSampleFile2.eml\"\n",
        "# FAISS_INDEX_FILE = \"/content/FAISS/faiss_index_classifications.idx\"\n",
        "# MAPPING_FILE = \"/content/FAISS/faiss_mapping.csv\"\n",
        "# EMBED_MODEL = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# # ‚úÖ Function to load FAISS index and mapping\n",
        "# def load_faiss():\n",
        "#     \"\"\"Loads the FAISS index and the mapping CSV.\"\"\"\n",
        "#     try:\n",
        "#         print(\"\\n‚úÖ Loading FAISS index...\")\n",
        "#         faiss_index = faiss.read_index(FAISS_INDEX_FILE)\n",
        "\n",
        "#         print(\"\\n‚úÖ Loading FAISS mapping...\")\n",
        "#         mapping_df = pd.read_csv(MAPPING_FILE)\n",
        "\n",
        "#         print(\"\\n‚úÖ FAISS and mapping loaded successfully!\")\n",
        "#         return faiss_index, mapping_df\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"‚ùå Error loading FAISS: {e}\")\n",
        "#         return None, None\n",
        "\n",
        "# # ‚úÖ FAISS search function\n",
        "# def search_faiss(embedding, faiss_index, mapping_df, top_k=5):\n",
        "#     \"\"\"Searches FAISS index and retrieves mapped classifications.\"\"\"\n",
        "#     # Ensure the embedding is in correct format\n",
        "#     embedding = embedding.reshape(1, -1).astype('float32')\n",
        "\n",
        "#     # Perform the FAISS search\n",
        "#     distances, indices = faiss_index.search(embedding, top_k)\n",
        "\n",
        "#     results = []\n",
        "#     for i in range(len(indices[0])):\n",
        "#         idx = indices[0][i]\n",
        "#         dist = distances[0][i]\n",
        "\n",
        "#         if idx < 0 or idx >= len(mapping_df):\n",
        "#             continue  # Skip invalid indices\n",
        "\n",
        "#         # ‚úÖ Retrieve the corresponding classification from the mapping\n",
        "#         # ‚úÖ Changed 'request_type' and 'sub_request_type' to 'id'\n",
        "#         # ‚úÖ Assuming 'id' column contains classification information\n",
        "#         file_name = mapping_df.iloc[idx]['file']\n",
        "#         classification_id = mapping_df.iloc[idx]['id'] # Assuming id is your classification\n",
        "\n",
        "#         results.append((file_name, dist, classification_id)) # Adjusted results format\n",
        "\n",
        "#     return results\n",
        "\n",
        "# # ‚úÖ Querying the EML file\n",
        "# def query_eml(file_path):\n",
        "#     \"\"\"Classifies and searches for similar emails.\"\"\"\n",
        "\n",
        "#     print(\"\\n‚úÖ Extracting EML content...\")\n",
        "#     eml_content = extract_eml_content(file_path)\n",
        "\n",
        "#     print(\"\\n‚úÖ Classifying with Gemini Pro...\")\n",
        "#     req_type, sub_req_type, reason = classify_with_gemini(eml_content)\n",
        "\n",
        "#     print(\"\\n‚úÖ Generating embedding...\")\n",
        "#     embedding = EMBED_MODEL.encode(eml_content)\n",
        "\n",
        "#     print(\"\\n‚úÖ Searching FAISS for similar emails...\")\n",
        "#     results = search_faiss(embedding, faiss_index, mapping_df)\n",
        "\n",
        "#     # === Display results\n",
        "#     print(\"\\nüîç **Query Results:**\")\n",
        "#     print(f\"üîπ **LLM Classification:**\")\n",
        "#     print(f\"   - Request Type: {req_type}\")\n",
        "#     print(f\"   - Sub Request Type: {sub_req_type}\")\n",
        "#     print(f\"   - Reason: {reason}\\n\")\n",
        "\n",
        "#     print(\"\\nüîπ **FAISS Similarity Results:**\")\n",
        "#     if results:\n",
        "#         # ‚úÖ Changed to unpack 3 values: file_name, dist, classification_id\n",
        "#         for file_name, dist, classification_id in results:\n",
        "#             print(f\"   - {file_name} (Distance: {dist:.4f})\")\n",
        "#             # ‚úÖ Assuming classification_id is used to display classification information\n",
        "#             print(f\"     - Classification ID: {classification_id}\")\n",
        "#     else:\n",
        "#         print(\"‚ö†Ô∏è No matching emails found.\")\n",
        "\n",
        "# # ‚úÖ Load FAISS and mapping\n",
        "# faiss_index, mapping_df = load_faiss()\n",
        "\n",
        "# # ‚úÖ Run the query\n",
        "# if faiss_index is not None and mapping_df is not None:\n",
        "#     query_eml(EML_FILE)\n",
        "# else:\n",
        "#     print(\"‚ùå FAISS index or mapping file not loaded successfully.\")\n"
      ],
      "metadata": {
        "id": "U5qbzW5ynvAw"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}